{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from dotenv import load_dotenv\n",
    "load_dotenv()\n",
    "\n",
    "os.environ[\"OPENAI_API_KEY\"] = os.getenv(\"OPENAI_API_KEY\")\n",
    "\n",
    "#LANGSMITH TRACING\n",
    "\n",
    "os.environ[\"LANGCHAIN_API_KEY\"] = os.getenv(\"LANGCHAIN_API_KEY\")\n",
    "os.environ['LANGCHIAN_TRACING_V2'] = \"true\"\n",
    "os.environ[\"LANGCHAIN_PROJECT\"] = os.getenv(\"LANGCHAIN_PROJECT\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[Document(metadata={'source': 'https://medium.com/around-the-prompt/what-is-langchain-and-why-should-i-care-as-a-developer-b2d952c42b28', 'title': 'What is Langchain and why should I care as a developer? | by Logan Kilpatrick | Around the Prompt | Medium', 'description': 'Langchain ü¶ú is one of the fastest growing open source projects in history, in large part due to the explosion of interest in LLM‚Äôs. This post explores some of the cool thing that langchain helps‚Ä¶', 'language': 'en'}, page_content='What is Langchain and why should I care as a developer? | by Logan Kilpatrick | Around the Prompt | MediumOpen in appSign upSign inWriteSign upSign inWhat is Langchain and why should I care as a developer?The worlds fastest growing language model application framework, packed with LLM tools and agent supportLogan Kilpatrick¬∑FollowPublished inAround the Prompt¬∑6 min read¬∑Jun 30, 2023--4ListenShareLangchain ü¶ú is one of the fastest growing open source projects in history, in large part due to the explosion of interest in LLM‚Äôs.This post explores some of the cool thing that langchain helps developers do from a 30,000 foot overview. It was written for my own benefit as I explored the framework and I hope it helps you if you are also curios where langchain might be useful.Some of the features that make langchain so powerful include allowing you to connect data to language models (like OpenAI‚Äôs GPT models via the API) and create agent workflows (more on agents later).[Quick disclaimer: this post represented my personal view, not my employers (shocking, I know). It was also written on my phone while on a 10 hour sleep deprived car ride so please excuse any silly mistakes üòÖ]Why does langchain exist? ü§îSimply put, there are many rough edges to working with languages models today. The entire ecosystem is still developing so for developers, there is generally a lack of sufficient tooling to make production deployments of languages models.Tasks like prompt chaining, logging, call backs, persistent memory, and efficient connections to multiple data sources come standard out of the box with langchain.Langchain also provides a model agnostic toolset that enables companies and developers to explore multiple LLM offerings and test what works best for their use cases. The best part is that you can do this in a single interface instead of having to linearly scale the size of a code base which each additional provider you try to support.Langchain‚Äôs community ‚≠êÔ∏èOne of the core things to look at when evaluating a tool is the community built around it. This is even more so true for open source projects like langchain. As of today, the project has over 51k stars on GitHub (a metric often used to assess the popularity of an open source project), 1 million downloads a month, and an active Discord / Twitter presence.Langchain also recently hit the 1,000 contributor milestone on their core repository which is a feat that few repository‚Äôs have accomplished and speaks to the openness of the projects as well as its long term viability. Langchain even uses the popular MIT license which allows developers to fork the code base and make their own version or even developer commercial products on top of the existing code.Quick interruption: my brother Chandler is working on a project where he creates custom hard cover AI art coffee table books for people based on the theme they want, it is so fricken cool! Check it out to support him:Custom (You Choose the Theme) AI Art Coffee Table BookInterested in AI? Want to explore what is possible and be inspired by AI art generated by DALL¬∑E 3 from OpenAI?Let‚Äôs‚Ä¶aiartbooks.gumroad.comCheck out the video I made which brings this article to life:Agents in Langchain ü§ñOne of the hottest ideas in the large language models space right now is the idea of agents. By using language models, you can essentially recreate a programmatic entity that has goals and tasks it can execute.Langchain makes creating agents using large language models simple through their agents API. Developers can use OpenAI functions or other means of executing tasks to enable to language model to take actions.There are many agent tools out there like AgentGPT and more. So what makes langchain useful in this case? For one, you have access to multiple tooling frameworks using a single interface. Further, you can leverage the plan and execute functionality which allows the model to create plans, execute tasks, and accomplish goals. This is especially useful when you are looking for the agent to become somewhat autonomous and try to accomplish a goal with little to no feedback from a human. While this sounds pretty scary in some contexts, the real impact of it today is pretty minimal given that todays models don‚Äôt usually succeed at these tasks over long time horizons (though of course this will get better over time).Memory with language models üß†Today, the most powerful LLM API is OpenAI‚Äôs API. The API is not stateful so each time you sent a request to generate a new chat message, you have to pass back any context that might be necessary to allow the model to answer the query at hand. Developers can do light weight things like store the message history in a Python list or write it to a text file but this doesn‚Äôt scale well.You could also spin up a vector database (special database just for Embeddings which are a numerical way of representing the meaning of text) but this often takes a bit of work. Langchain has a memory module which provides plug and play access to multiple data store which allow you to save the message history of a conversation automatically further reducing the friction to create a chatbot for example.Langchain currently supports 10 different database integrations with more surely to come soon giving you lots of flexibility in how you want to save message history. I also expect that the options to do this outside langchain will get much better over time as there are already a few open source projects specifically designed to help make the process of managing chat history and truncation simpler.A quick note on truncation: this is the process of taking the message history and continually narrowing it down in order to stay within the language models context window. There‚Äôs lots of different ways of doing it, and in fact ChatGPT has a custom approach, but there is no silver bullet here since you will always end up having to omit important info you care about. This is why Embeddings and memory through langchain can be so useful.Comparison tools üîçOne of the last core parts of langchain I will mention is the ability to dynamically compare models and prompts. This can be extremely useful when trying to assess which model might be better for a specific task. For example, you might want to have multiple GPT 3.5-turbo and GPT-4 models setup twitch different system messages and use the comparison tool to see which output better aligns with your use case. This will take a little bit of work but it‚Äôs one of the kalt useful ways to A/B test different setups in a production environment.Everyone loves prompt engineering. Well, the dirty secret is that no one really like prompt engineering, it‚Äôs kind of a hassle. I just want the model to work the way it‚Äôs supposed to and do what I want. But life isn‚Äôt perfect and sometimes you have to do some of the work yourself. That‚Äôs where the evaluator comes in which is part of langchains evaluation module. It has a few different functions for operations like ‚ÄúPairwiseStringEvalChain‚Äù (more details in the docs).They even have a benchmarking template notebook which at first glance appears to be something which I will be using in my own workflows. One quick random thought: the models themselves are usually better at prompt tuning than we are. Sometimes the esoteric, detailed, and clear prompts are not easy for us to come up with but the model can really do a great job. If you are getting stuck with prompting issues, trying asking GPT-4 to improve the prompt iteratively with you.Closing thoughts üéôÔ∏èFirst off, I hope this was useful. I had been neglecting to try langchain since I‚Äôve been busy with a hundred other things and I‚Äôm glad I finally had the time to check it out (albeit while on vacation from those 100 other things). My overall take is that langchain definitely solves problems today. My forward looking statement is that I imagine the LLM API‚Äôs will do more and more over time which will make langchain either much less useful. It‚Äôs also entirely possible that it ends up as the interface to LLM‚Äôs since people want the platform agnostic setup which would make sense. One thing is for sure, Harrison and the langchain community have done an incredible job building what they have so far, it‚Äôs clearly providing value and I‚Äôm glad they are doing this work.ChatGPTGpt 4OpenAILangchainLanguage Model----4Published in Around the Prompt27 Followers¬∑Last published\\xa0Nov 18, 2024‚ÄòAround the Prompt‚Äô goes deep, peeling back the layers of AI innovation to reveal the hidden gems, the untapped potential, based on conversations with leading experts.FollowWritten by Logan Kilpatrick2.7K Followers¬∑4 FollowingLead product for Google AI Studio, working on the Gemini API, and AGI. Ex-OpenAI.FollowResponses (4)See all responsesHelpStatusAboutCareersPressBlogPrivacyTermsText to speechTeams\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n')]"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Data ingestion --->  From website--> scraping the data\n",
    "\n",
    "from langchain_community.document_loaders import WebBaseLoader\n",
    "\n",
    "loader = WebBaseLoader(\"https://medium.com/around-the-prompt/what-is-langchain-and-why-should-i-care-as-a-developer-b2d952c42b28\")       #want to take url from user on streamlit-- chatgppt command\n",
    "\n",
    "docs = loader.load()\n",
    "\n",
    "docs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[Document(metadata={'source': 'https://medium.com/around-the-prompt/what-is-langchain-and-why-should-i-care-as-a-developer-b2d952c42b28', 'title': 'What is Langchain and why should I care as a developer? | by Logan Kilpatrick | Around the Prompt | Medium', 'description': 'Langchain ü¶ú is one of the fastest growing open source projects in history, in large part due to the explosion of interest in LLM‚Äôs. This post explores some of the cool thing that langchain helps‚Ä¶', 'language': 'en'}, page_content='What is Langchain and why should I care as a developer? | by Logan Kilpatrick | Around the Prompt | MediumOpen in appSign upSign inWriteSign upSign inWhat is Langchain and why should I care as a developer?The worlds fastest growing language model application framework, packed with LLM tools and agent supportLogan Kilpatrick¬∑FollowPublished inAround the Prompt¬∑6 min read¬∑Jun 30, 2023--4ListenShareLangchain ü¶ú is one of the fastest growing open source projects in history, in large part due to the explosion of interest in LLM‚Äôs.This post explores some of the cool thing that langchain helps developers do from a 30,000 foot overview. It was written for my own benefit as I explored the framework and I hope it helps you if you are also curios where langchain might be useful.Some of the features that make langchain so powerful include allowing you to connect data to language models (like OpenAI‚Äôs GPT models via the API) and create agent workflows (more on agents later).[Quick disclaimer: this'),\n",
       " Document(metadata={'source': 'https://medium.com/around-the-prompt/what-is-langchain-and-why-should-i-care-as-a-developer-b2d952c42b28', 'title': 'What is Langchain and why should I care as a developer? | by Logan Kilpatrick | Around the Prompt | Medium', 'description': 'Langchain ü¶ú is one of the fastest growing open source projects in history, in large part due to the explosion of interest in LLM‚Äôs. This post explores some of the cool thing that langchain helps‚Ä¶', 'language': 'en'}, page_content='make langchain so powerful include allowing you to connect data to language models (like OpenAI‚Äôs GPT models via the API) and create agent workflows (more on agents later).[Quick disclaimer: this post represented my personal view, not my employers (shocking, I know). It was also written on my phone while on a 10 hour sleep deprived car ride so please excuse any silly mistakes üòÖ]Why does langchain exist? ü§îSimply put, there are many rough edges to working with languages models today. The entire ecosystem is still developing so for developers, there is generally a lack of sufficient tooling to make production deployments of languages models.Tasks like prompt chaining, logging, call backs, persistent memory, and efficient connections to multiple data sources come standard out of the box with langchain.Langchain also provides a model agnostic toolset that enables companies and developers to explore multiple LLM offerings and test what works best for their use cases. The best part is that'),\n",
       " Document(metadata={'source': 'https://medium.com/around-the-prompt/what-is-langchain-and-why-should-i-care-as-a-developer-b2d952c42b28', 'title': 'What is Langchain and why should I care as a developer? | by Logan Kilpatrick | Around the Prompt | Medium', 'description': 'Langchain ü¶ú is one of the fastest growing open source projects in history, in large part due to the explosion of interest in LLM‚Äôs. This post explores some of the cool thing that langchain helps‚Ä¶', 'language': 'en'}, page_content='langchain.Langchain also provides a model agnostic toolset that enables companies and developers to explore multiple LLM offerings and test what works best for their use cases. The best part is that you can do this in a single interface instead of having to linearly scale the size of a code base which each additional provider you try to support.Langchain‚Äôs community ‚≠êÔ∏èOne of the core things to look at when evaluating a tool is the community built around it. This is even more so true for open source projects like langchain. As of today, the project has over 51k stars on GitHub (a metric often used to assess the popularity of an open source project), 1 million downloads a month, and an active Discord / Twitter presence.Langchain also recently hit the 1,000 contributor milestone on their core repository which is a feat that few repository‚Äôs have accomplished and speaks to the openness of the projects as well as its long term viability. Langchain even uses the popular MIT license which'),\n",
       " Document(metadata={'source': 'https://medium.com/around-the-prompt/what-is-langchain-and-why-should-i-care-as-a-developer-b2d952c42b28', 'title': 'What is Langchain and why should I care as a developer? | by Logan Kilpatrick | Around the Prompt | Medium', 'description': 'Langchain ü¶ú is one of the fastest growing open source projects in history, in large part due to the explosion of interest in LLM‚Äôs. This post explores some of the cool thing that langchain helps‚Ä¶', 'language': 'en'}, page_content='repository which is a feat that few repository‚Äôs have accomplished and speaks to the openness of the projects as well as its long term viability. Langchain even uses the popular MIT license which allows developers to fork the code base and make their own version or even developer commercial products on top of the existing code.Quick interruption: my brother Chandler is working on a project where he creates custom hard cover AI art coffee table books for people based on the theme they want, it is so fricken cool! Check it out to support him:Custom (You Choose the Theme) AI Art Coffee Table BookInterested in AI? Want to explore what is possible and be inspired by AI art generated by DALL¬∑E 3 from OpenAI?Let‚Äôs‚Ä¶aiartbooks.gumroad.comCheck out the video I made which brings this article to life:Agents in Langchain ü§ñOne of the hottest ideas in the large language models space right now is the idea of agents. By using language models, you can essentially recreate a programmatic entity that has'),\n",
       " Document(metadata={'source': 'https://medium.com/around-the-prompt/what-is-langchain-and-why-should-i-care-as-a-developer-b2d952c42b28', 'title': 'What is Langchain and why should I care as a developer? | by Logan Kilpatrick | Around the Prompt | Medium', 'description': 'Langchain ü¶ú is one of the fastest growing open source projects in history, in large part due to the explosion of interest in LLM‚Äôs. This post explores some of the cool thing that langchain helps‚Ä¶', 'language': 'en'}, page_content='in Langchain ü§ñOne of the hottest ideas in the large language models space right now is the idea of agents. By using language models, you can essentially recreate a programmatic entity that has goals and tasks it can execute.Langchain makes creating agents using large language models simple through their agents API. Developers can use OpenAI functions or other means of executing tasks to enable to language model to take actions.There are many agent tools out there like AgentGPT and more. So what makes langchain useful in this case? For one, you have access to multiple tooling frameworks using a single interface. Further, you can leverage the plan and execute functionality which allows the model to create plans, execute tasks, and accomplish goals. This is especially useful when you are looking for the agent to become somewhat autonomous and try to accomplish a goal with little to no feedback from a human. While this sounds pretty scary in some contexts, the real impact of it today is'),\n",
       " Document(metadata={'source': 'https://medium.com/around-the-prompt/what-is-langchain-and-why-should-i-care-as-a-developer-b2d952c42b28', 'title': 'What is Langchain and why should I care as a developer? | by Logan Kilpatrick | Around the Prompt | Medium', 'description': 'Langchain ü¶ú is one of the fastest growing open source projects in history, in large part due to the explosion of interest in LLM‚Äôs. This post explores some of the cool thing that langchain helps‚Ä¶', 'language': 'en'}, page_content='for the agent to become somewhat autonomous and try to accomplish a goal with little to no feedback from a human. While this sounds pretty scary in some contexts, the real impact of it today is pretty minimal given that todays models don‚Äôt usually succeed at these tasks over long time horizons (though of course this will get better over time).Memory with language models üß†Today, the most powerful LLM API is OpenAI‚Äôs API. The API is not stateful so each time you sent a request to generate a new chat message, you have to pass back any context that might be necessary to allow the model to answer the query at hand. Developers can do light weight things like store the message history in a Python list or write it to a text file but this doesn‚Äôt scale well.You could also spin up a vector database (special database just for Embeddings which are a numerical way of representing the meaning of text) but this often takes a bit of work. Langchain has a memory module which provides plug and play'),\n",
       " Document(metadata={'source': 'https://medium.com/around-the-prompt/what-is-langchain-and-why-should-i-care-as-a-developer-b2d952c42b28', 'title': 'What is Langchain and why should I care as a developer? | by Logan Kilpatrick | Around the Prompt | Medium', 'description': 'Langchain ü¶ú is one of the fastest growing open source projects in history, in large part due to the explosion of interest in LLM‚Äôs. This post explores some of the cool thing that langchain helps‚Ä¶', 'language': 'en'}, page_content='(special database just for Embeddings which are a numerical way of representing the meaning of text) but this often takes a bit of work. Langchain has a memory module which provides plug and play access to multiple data store which allow you to save the message history of a conversation automatically further reducing the friction to create a chatbot for example.Langchain currently supports 10 different database integrations with more surely to come soon giving you lots of flexibility in how you want to save message history. I also expect that the options to do this outside langchain will get much better over time as there are already a few open source projects specifically designed to help make the process of managing chat history and truncation simpler.A quick note on truncation: this is the process of taking the message history and continually narrowing it down in order to stay within the language models context window. There‚Äôs lots of different ways of doing it, and in fact ChatGPT'),\n",
       " Document(metadata={'source': 'https://medium.com/around-the-prompt/what-is-langchain-and-why-should-i-care-as-a-developer-b2d952c42b28', 'title': 'What is Langchain and why should I care as a developer? | by Logan Kilpatrick | Around the Prompt | Medium', 'description': 'Langchain ü¶ú is one of the fastest growing open source projects in history, in large part due to the explosion of interest in LLM‚Äôs. This post explores some of the cool thing that langchain helps‚Ä¶', 'language': 'en'}, page_content='the process of taking the message history and continually narrowing it down in order to stay within the language models context window. There‚Äôs lots of different ways of doing it, and in fact ChatGPT has a custom approach, but there is no silver bullet here since you will always end up having to omit important info you care about. This is why Embeddings and memory through langchain can be so useful.Comparison tools üîçOne of the last core parts of langchain I will mention is the ability to dynamically compare models and prompts. This can be extremely useful when trying to assess which model might be better for a specific task. For example, you might want to have multiple GPT 3.5-turbo and GPT-4 models setup twitch different system messages and use the comparison tool to see which output better aligns with your use case. This will take a little bit of work but it‚Äôs one of the kalt useful ways to A/B test different setups in a production environment.Everyone loves prompt engineering.'),\n",
       " Document(metadata={'source': 'https://medium.com/around-the-prompt/what-is-langchain-and-why-should-i-care-as-a-developer-b2d952c42b28', 'title': 'What is Langchain and why should I care as a developer? | by Logan Kilpatrick | Around the Prompt | Medium', 'description': 'Langchain ü¶ú is one of the fastest growing open source projects in history, in large part due to the explosion of interest in LLM‚Äôs. This post explores some of the cool thing that langchain helps‚Ä¶', 'language': 'en'}, page_content='better aligns with your use case. This will take a little bit of work but it‚Äôs one of the kalt useful ways to A/B test different setups in a production environment.Everyone loves prompt engineering. Well, the dirty secret is that no one really like prompt engineering, it‚Äôs kind of a hassle. I just want the model to work the way it‚Äôs supposed to and do what I want. But life isn‚Äôt perfect and sometimes you have to do some of the work yourself. That‚Äôs where the evaluator comes in which is part of langchains evaluation module. It has a few different functions for operations like ‚ÄúPairwiseStringEvalChain‚Äù (more details in the docs).They even have a benchmarking template notebook which at first glance appears to be something which I will be using in my own workflows. One quick random thought: the models themselves are usually better at prompt tuning than we are. Sometimes the esoteric, detailed, and clear prompts are not easy for us to come up with but the model can really do a great job.'),\n",
       " Document(metadata={'source': 'https://medium.com/around-the-prompt/what-is-langchain-and-why-should-i-care-as-a-developer-b2d952c42b28', 'title': 'What is Langchain and why should I care as a developer? | by Logan Kilpatrick | Around the Prompt | Medium', 'description': 'Langchain ü¶ú is one of the fastest growing open source projects in history, in large part due to the explosion of interest in LLM‚Äôs. This post explores some of the cool thing that langchain helps‚Ä¶', 'language': 'en'}, page_content='the models themselves are usually better at prompt tuning than we are. Sometimes the esoteric, detailed, and clear prompts are not easy for us to come up with but the model can really do a great job. If you are getting stuck with prompting issues, trying asking GPT-4 to improve the prompt iteratively with you.Closing thoughts üéôÔ∏èFirst off, I hope this was useful. I had been neglecting to try langchain since I‚Äôve been busy with a hundred other things and I‚Äôm glad I finally had the time to check it out (albeit while on vacation from those 100 other things). My overall take is that langchain definitely solves problems today. My forward looking statement is that I imagine the LLM API‚Äôs will do more and more over time which will make langchain either much less useful. It‚Äôs also entirely possible that it ends up as the interface to LLM‚Äôs since people want the platform agnostic setup which would make sense. One thing is for sure, Harrison and the langchain community have done an incredible'),\n",
       " Document(metadata={'source': 'https://medium.com/around-the-prompt/what-is-langchain-and-why-should-i-care-as-a-developer-b2d952c42b28', 'title': 'What is Langchain and why should I care as a developer? | by Logan Kilpatrick | Around the Prompt | Medium', 'description': 'Langchain ü¶ú is one of the fastest growing open source projects in history, in large part due to the explosion of interest in LLM‚Äôs. This post explores some of the cool thing that langchain helps‚Ä¶', 'language': 'en'}, page_content='that it ends up as the interface to LLM‚Äôs since people want the platform agnostic setup which would make sense. One thing is for sure, Harrison and the langchain community have done an incredible job building what they have so far, it‚Äôs clearly providing value and I‚Äôm glad they are doing this work.ChatGPTGpt 4OpenAILangchainLanguage Model----4Published in Around the Prompt27 Followers¬∑Last published\\xa0Nov 18, 2024‚ÄòAround the Prompt‚Äô goes deep, peeling back the layers of AI innovation to reveal the hidden gems, the untapped potential, based on conversations with leading experts.FollowWritten by Logan Kilpatrick2.7K Followers¬∑4 FollowingLead product for Google AI Studio, working on the Gemini API, and AGI. Ex-OpenAI.FollowResponses (4)See all responsesHelpStatusAboutCareersPressBlogPrivacyTermsText to speechTeams')]"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#data splitting of docs\n",
    "\n",
    "from langchain_text_splitters import RecursiveCharacterTextSplitter\n",
    "text_splitter = RecursiveCharacterTextSplitter(chunk_size = 1000, chunk_overlap=200)\n",
    "documents = text_splitter.split_documents(docs)\n",
    "documents"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "#converting the text vector to the embeddings\n",
    "from langchain_openai import OpenAIEmbeddings\n",
    "embeddings = OpenAIEmbeddings()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "#storing the embeddings into a vector database\n",
    "\n",
    "from langchain_community.vectorstores import FAISS\n",
    "vectorstoredb = FAISS.from_documents(documents, embeddings)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<langchain_community.vectorstores.faiss.FAISS at 0x273dba9c7f0>"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vectorstoredb"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "first approch where we give context and query manually"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_openai import ChatOpenAI\n",
    "llm = ChatOpenAI(model = \"gpt-4o\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "ChatOpenAI(client=<openai.resources.chat.completions.Completions object at 0x00000273DBA9CEB0>, async_client=<openai.resources.chat.completions.AsyncCompletions object at 0x00000273DBA9FFD0>, root_client=<openai.OpenAI object at 0x00000273DBA9C6D0>, root_async_client=<openai.AsyncOpenAI object at 0x00000273DBA9CF10>, model_name='gpt-4o', model_kwargs={}, openai_api_key=SecretStr('**********'))"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "llm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "RunnableBinding(bound=RunnableBinding(bound=RunnableAssign(mapper={\n",
       "  context: RunnableLambda(format_docs)\n",
       "}), kwargs={}, config={'run_name': 'format_inputs'}, config_factories=[])\n",
       "| ChatPromptTemplate(input_variables=['context'], input_types={}, partial_variables={}, messages=[HumanMessagePromptTemplate(prompt=PromptTemplate(input_variables=['context'], input_types={}, partial_variables={}, template='\\n    Answer the following question based on the provided context, which is easy for user to understand:\\n    <context>\\n    {context}\\n    </context>\\n    \\n    '), additional_kwargs={})])\n",
       "| ChatOpenAI(client=<openai.resources.chat.completions.Completions object at 0x00000273DBA9CEB0>, async_client=<openai.resources.chat.completions.AsyncCompletions object at 0x00000273DBA9FFD0>, root_client=<openai.OpenAI object at 0x00000273DBA9C6D0>, root_async_client=<openai.AsyncOpenAI object at 0x00000273DBA9CF10>, model_name='gpt-4o', model_kwargs={}, openai_api_key=SecretStr('**********'))\n",
       "| StrOutputParser(), kwargs={}, config={'run_name': 'stuff_documents_chain'}, config_factories=[])"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from langchain.chains.combine_documents import create_stuff_documents_chain\n",
    "from langchain_core.prompts import ChatPromptTemplate\n",
    "\n",
    "\n",
    "prompt = ChatPromptTemplate.from_template(\n",
    "    \"\"\"\n",
    "    Answer the following question based on the provided context, which is easy for user to understand:\n",
    "    <context>\n",
    "    {context}\n",
    "    </context>\n",
    "    \n",
    "    \"\"\"\n",
    "\n",
    ")\n",
    "\n",
    "document_chain = create_stuff_documents_chain(llm,prompt)\n",
    "\n",
    "document_chain"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'from langchain_core.documents import Document\\n\\ndocument_chain.invoke({\\n    \"input\":\"what are Langsmith two usage limits\",\\n    \"context\":[Document(page_content=\"LangSmith has two usage limits: total traces and extended traces. These correspond to the two metrics we\\'ve been tracking on our usage graph. \")]\\n})\\n'"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\"\"\"from langchain_core.documents import Document\n",
    "\n",
    "document_chain.invoke({\n",
    "    \"input\":\"what are Langsmith two usage limits\",\n",
    "    \"context\":[Document(page_content=\"LangSmith has two usage limits: total traces and extended traces. These correspond to the two metrics we've been tracking on our usage graph. \")]\n",
    "})\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Dynamically select the relevent document and pass for the input provided by the user"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<langchain_community.vectorstores.faiss.FAISS at 0x273dba9c7f0>"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vectorstoredb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "RunnableBinding(bound=RunnableAssign(mapper={\n",
       "  context: RunnableBinding(bound=RunnableLambda(lambda x: x['input'])\n",
       "           | VectorStoreRetriever(tags=['FAISS', 'OpenAIEmbeddings'], vectorstore=<langchain_community.vectorstores.faiss.FAISS object at 0x00000273DBA9C7F0>, search_kwargs={}), kwargs={}, config={'run_name': 'retrieve_documents'}, config_factories=[])\n",
       "})\n",
       "| RunnableAssign(mapper={\n",
       "    answer: RunnableBinding(bound=RunnableBinding(bound=RunnableAssign(mapper={\n",
       "              context: RunnableLambda(format_docs)\n",
       "            }), kwargs={}, config={'run_name': 'format_inputs'}, config_factories=[])\n",
       "            | ChatPromptTemplate(input_variables=['context'], input_types={}, partial_variables={}, messages=[HumanMessagePromptTemplate(prompt=PromptTemplate(input_variables=['context'], input_types={}, partial_variables={}, template='\\n    Answer the following question based on the provided context, which is easy for user to understand:\\n    <context>\\n    {context}\\n    </context>\\n    \\n    '), additional_kwargs={})])\n",
       "            | ChatOpenAI(client=<openai.resources.chat.completions.Completions object at 0x00000273DBA9CEB0>, async_client=<openai.resources.chat.completions.AsyncCompletions object at 0x00000273DBA9FFD0>, root_client=<openai.OpenAI object at 0x00000273DBA9C6D0>, root_async_client=<openai.AsyncOpenAI object at 0x00000273DBA9CF10>, model_name='gpt-4o', model_kwargs={}, openai_api_key=SecretStr('**********'))\n",
       "            | StrOutputParser(), kwargs={}, config={'run_name': 'stuff_documents_chain'}, config_factories=[])\n",
       "  }), kwargs={}, config={'run_name': 'retrieval_chain'}, config_factories=[])"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "retriever = vectorstoredb.as_retriever()\n",
    "from langchain.chains import create_retrieval_chain\n",
    "retriever_chain = create_retrieval_chain(retriever, document_chain)\n",
    "retriever_chain"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Getting the response\n",
    "\n",
    "response = retriever_chain.invoke({\"input\":\"what is langchain\"})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"Langchain is an open-source framework that helps developers work with large language models (LLMs) by providing a flexible and simplified toolset. It allows you to connect data with models like OpenAI's GPT, create agent workflows, and test multiple LLM offerings seamlessly. By using Langchain, developers can manage tasks such as prompt chaining, logging, and connecting to data sources more efficiently. As a developer, Langchain is valuable because it offers a single interface to manage different model technologies, boasting a large community that supports its growth and ensures its long-term viability. Additionally, with its agent API, developers can create autonomous programmatic entities, making it possible for models to plan, execute tasks, and accomplish goals independently. The framework's popularity is reflected in its 51k stars on GitHub and over a million downloads per month, illustrating its usefulness and the trust it's earned within the developer community.\""
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "response['answer']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "scraper",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
